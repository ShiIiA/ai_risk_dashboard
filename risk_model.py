# -*- coding: utf-8 -*-
"""risk_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kQnIB5CyS0jLMgY7YceygO79mktuv8pG
"""

def calculate_risk_score(misclassification_rate, dataset_bias, explainability_score, fairness_score):
    """
    Calculates AI risk score based on key metrics.

    :param misclassification_rate: Error rate of AI (0 to 1)
    :param dataset_bias: Bias in dataset (0 to 1)
    :param explainability_score: SHAP-based score (0 to 1)
    :param fairness_score: Fairness metric score (0 to 1)
    :return: Risk Score (0 to 100)
    """
    weight_misclass = 0.4
    weight_bias = 0.3
    weight_explainability = 0.15
    weight_fairness = 0.15

    risk_score = (
        misclassification_rate * weight_misclass +
        dataset_bias * weight_bias +
        (1 - explainability_score) * weight_explainability +
        (1 - fairness_score) * weight_fairness
    ) * 100

    return round(risk_score, 2)